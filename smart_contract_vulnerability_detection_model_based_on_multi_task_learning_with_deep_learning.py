# -*- coding: utf-8 -*-
"""Smart Contract Vulnerability Detection Model Based on Multi-Task Learning with Deep Learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17-fa4viLOUhk0kS8icp8wGFjxMoPZQdr
"""
 
import pandas as pd

# Update the paths as per your directory structure in Google Drive
train_path = '/Dataset/train.parquet'
validation_path = '/Dataset/validation.parquet'
test_path = '/Dataset/test.parquet'

# Load the datasets
df_train = pd.read_parquet(train_path)
df_validation = pd.read_parquet(validation_path)
df_test = pd.read_parquet(test_path)

print(df_train.columns)
print(df_train.head())

X_train_raw = df_train['source_code']
X_validation_raw = df_validation['source_code']
X_test_raw = df_test['source_code']

def extract_labels(df, column_name='overlapping'):
    # A simplified example for binary classification based on presence of any vulnerability
    return df[column_name].apply(lambda x: 1 if x else 0).values

y_train = extract_labels(df_train)
y_validation = extract_labels(df_validation)
y_test = extract_labels(df_test)

"""**CNN**"""

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import roc_curve, auc, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout
from tensorflow.keras.regularizers import l2


train_path = '/Dataset/train.parquet'
validation_path = '/Dataset/validation.parquet'
test_path = '/Dataset/test.parquet'
# Load your dataset
df_train = pd.read_parquet(train_path)
df_validation = pd.read_parquet(validation_path)
df_test = pd.read_parquet(test_path)


df_merged = pd.concat([df_train, df_validation, df_test]).drop_duplicates(subset='source_code')


X_raw = df_merged['source_code']
y = df_merged['overlapping'].apply(lambda x: 1 if x else 0).values

X_train_raw, X_test_raw, y_train, y_test = train_test_split(X_raw, y, test_size=0.2, random_state=42)

vectorizer = TfidfVectorizer(max_features=1000)
X_train = vectorizer.fit_transform(X_train_raw).toarray()
X_test = vectorizer.transform(X_test_raw).toarray()

print(X_train.shape, X_test.shape)


X_train_cnn = np.expand_dims(X_train, axis=-1)
X_test_cnn = np.expand_dims(X_test, axis=-1)

print(X_train_cnn.shape, X_test_cnn.shape)

# Define a simpler CNN Model with regularization
cnn_model = Sequential()
cnn_model.add(Conv1D(filters=16, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1), kernel_regularizer=l2(0.01)))
cnn_model.add(MaxPooling1D(pool_size=2))
cnn_model.add(Flatten())
cnn_model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))
cnn_model.add(Dropout(0.5))
cnn_model.add(Dense(1, activation='sigmoid'))

cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
cnn_model.summary()


from tensorflow.keras.callbacks import EarlyStopping

early_stopping = EarlyStopping(patience=5, restore_best_weights=True)
history = cnn_model.fit(X_train_cnn, y_train,
                        epochs=100, # Increase epochs
                        batch_size=32,
                        validation_split=0.2,
                        callbacks=[early_stopping])


loss, accuracy = cnn_model.evaluate(X_test_cnn, y_test)
print(f"Test Loss (CNN): {loss}")
print(f"Test Accuracy (CNN): {accuracy}")


y_test_pred_proba = cnn_model.predict(X_test_cnn).ravel()
# Predicted classes for Confusion Matrix
y_test_pred = (y_test_pred_proba > 0.5).astype(int)



def plot_roc_curve(y_true, y_pred_prob):
    """
    y_true: array-like, true binary labels
    y_pred_prob: array-like, predicted probabilities for the positive class
    """
    fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)
    roc_auc = auc(fpr, tpr)

    plt.figure(figsize=(8, 8))
    plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], color='grey', lw=2, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc="lower right")
    plt.show()


plot_roc_curve(y_test, y_test_pred_proba)


def plot_confusion_matrix(y_true, y_pred):
    """
    y_true: array-like, true labels
    y_pred: array-like, predicted labels
    """
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='coolwarm', linewidths=0.5, linecolor='black')
    plt.title('Confusion Matrix')
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.show()


plot_confusion_matrix(y_test, y_test_pred)

def plot_training_history(history):
    plt.figure(figsize=(10, 5))
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Training and Validation Loss Over Epochs')
    plt.legend()
    plt.show()


plot_training_history(history)



"""**RNN**"""

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import roc_curve, auc, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense
from tensorflow.keras.callbacks import EarlyStopping

train_path = '/Dataset/train.parquet'
validation_path = '/Dataset/validation.parquet'
test_path = '/Dataset/test.parquet'


df_train = pd.read_parquet(train_path)
df_validation = pd.read_parquet(validation_path)
df_test = pd.read_parquet(test_path)

df_merged = pd.concat([df_train, df_validation, df_test]).drop_duplicates(subset='source_code')

X_raw = df_merged['source_code']
y = df_merged['overlapping'].apply(lambda x: 1 if x else 0).values

X_train_raw, X_test_raw, y_train, y_test = train_test_split(X_raw, y, test_size=0.2, random_state=42)

vectorizer = TfidfVectorizer(max_features=1000)
X_train = vectorizer.fit_transform(X_train_raw).toarray()

X_test = vectorizer.transform(X_test_raw).toarray()


rnn_model = Sequential()
rnn_model.add(Embedding(input_dim=1000, output_dim=128, input_length=X_train.shape[1]))
rnn_model.add(LSTM(units=64))
rnn_model.add(Dense(1, activation='sigmoid'))

rnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

rnn_model.summary()

early_stopping = EarlyStopping(patience=5, restore_best_weights=True)
history_rnn = rnn_model.fit(X_train, y_train,
                            epochs=10,
                            batch_size=32,
                            validation_split=0.2,
                            callbacks=[early_stopping])

loss_rnn, accuracy_rnn = rnn_model.evaluate(X_test, y_test)
print(f"Test Loss (RNN): {loss_rnn}")
print(f"Test Accuracy (RNN): {accuracy_rnn}")


def plot_roc_curve(y_true, y_pred_prob):
    fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)
    roc_auc = auc(fpr, tpr)

    plt.figure(figsize=(8, 8))
    plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], color='grey', lw=2, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc="lower right")
    plt.show()

def plot_confusion_matrix(y_true, y_pred):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='coolwarm', linewidths=0.5, linecolor='black')
    plt.title('Confusion Matrix')
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.show()


def plot_training_history(history):
    plt.figure(figsize=(10, 5))
    plt.plot(history.history['accuracy'], label='Training Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.title('Training and Validation Accuracy Over Epochs')
    plt.legend()
    plt.show()


plot_roc_curve(y_test, rnn_model.predict(X_test).ravel())
plot_confusion_matrix(y_test, rnn_model.predict(X_test).ravel().round())
plot_training_history(history_rnn)